{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\me\\anaconda3\\lib\\site-packages (from selenium) (1.25.9)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "Collecting selenium\n",
      "  Using cached selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied (use --upgrade to upgrade): selenium from https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl#sha256=2d7131d7bc5a5b99a2d9b04aaf2612c411b03b8ca1b1ee8d3de5845a9be2cb3c in c:\\users\\me\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: urllib3 in c:\\users\\me\\anaconda3\\lib\\site-packages (from selenium) (1.25.9)\n"
     ]
    }
   ],
   "source": [
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "browser_path = 'D:/Desktop/chromedriver.exe'\n",
    "# setting the chromedriver path and initializing driver\n",
    "driver = webdriver.Chrome(executable_path=browser_path)\n",
    "# create master df to append to\n",
    "master_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import random\n",
    "def sleep_for(opt1, opt2):\n",
    "    time_for = random.uniform(opt1, opt2)\n",
    "    time_for_int = int(round(time_for))\n",
    "    sleep(abs(time_for_int - time_for))\n",
    "    for i in range(time_for_int, 0, -1):\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "urls = ['https://twitter.com/search?q=simpsons%20(predicted%20OR%20covid)&src=typed_query']\n",
    "# how many times should the browser scroll down\n",
    "scroll_down_num = 4  \n",
    "# the element we are obtaining from the webpage\n",
    "post_element_xpath = '//div/div/article/div/div'\n",
    "# loop through your list of urls\n",
    "for url in pbar(urls):\n",
    "    driver.get(url)\n",
    "    sleep_for(10, 15)  # sleep a while\n",
    "    # scroll x number of times\n",
    "    for i in range(0, scroll_down_num):\n",
    "        # scroll down\n",
    "        driver.find_element_by_xpath('//body').send_keys(Keys.END)\n",
    "        sleep_for(4, 7)\n",
    "    # get a list of tweets\n",
    "    post_list = driver.find_elements_by_xpath(post_element_xpath)\n",
    "    # get the text only from each element\n",
    "    post_text = [x.text for x in post_list]\n",
    "    # create temporary dataset of each tweet\n",
    "    temp_df = pd.DataFrame(post_text, columns={'all_text'})\n",
    "    # append the temporary dataset to the dataset we will save\n",
    "    master_df = master_df.append(temp_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accidental Partridge\\n@AccidentalP\\n·\\nNov 1\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DP\\n@djcp87\\n·\\nNov 1\\n“The Simpson’s Predicte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002\\n@baleriebear\\n·\\n19h\\nquick everybody che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waluigi Galleani\\n@Thedoomscrolls\\n·\\n18h\\nthe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dan Povenmire\\n@DanPovenmire\\n·\\nOct 31\\nI cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Indie (COMMS OPEN)\\n@burntcinnabun\\n·\\nOct 31\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>appaboy\\n@appaboy\\n·\\nNov 3\\ni cant believe si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Snoc Makes Friends\\n@SnocHog\\n·\\n18h\\nthe simp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Leezer Beam\\n@pickleknee\\n·\\nNov 1\\nWow. Simps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BryBryBlessed\\n@BryBryBlessed\\n·\\n18h\\nReplyin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Simpsons Predicted Evey Word\\n@SimpsonAllW...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             all_text\n",
       "0   Accidental Partridge\\n@AccidentalP\\n·\\nNov 1\\n...\n",
       "1   DP\\n@djcp87\\n·\\nNov 1\\n“The Simpson’s Predicte...\n",
       "2   002\\n@baleriebear\\n·\\n19h\\nquick everybody che...\n",
       "3   Waluigi Galleani\\n@Thedoomscrolls\\n·\\n18h\\nthe...\n",
       "4   Dan Povenmire\\n@DanPovenmire\\n·\\nOct 31\\nI cal...\n",
       "5   Indie (COMMS OPEN)\\n@burntcinnabun\\n·\\nOct 31\\...\n",
       "6   appaboy\\n@appaboy\\n·\\nNov 3\\ni cant believe si...\n",
       "7   Snoc Makes Friends\\n@SnocHog\\n·\\n18h\\nthe simp...\n",
       "8   Leezer Beam\\n@pickleknee\\n·\\nNov 1\\nWow. Simps...\n",
       "9   BryBryBlessed\\n@BryBryBlessed\\n·\\n18h\\nReplyin...\n",
       "10  The Simpsons Predicted Evey Word\\n@SimpsonAllW..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             all_text  \\\n",
      "0                          “STOP GETTING BOND WRONG!”   \n",
      "1                         “The Simpson’s Predicted it   \n",
      "2   quick everybody check the simpsons episodes to...   \n",
      "3            the Simpsons predicted this would happen   \n",
      "4    I called it!  You are not going to believe this!   \n",
      "5   There's gonna be another simpsons-like conspir...   \n",
      "6   i cant believe simpsons predicted that humans ...   \n",
      "7             the simpsons predicted deez nuts guy!!!   \n",
      "8                         Wow. Simpsons predicted it.   \n",
      "9            The simpsons predicted the future lowkey   \n",
      "10                    The Simpsons predicted disposal   \n",
      "\n",
      "                            username            handle    date  reply_to  \\\n",
      "0               Accidental Partridge      @AccidentalP   Nov 1     False   \n",
      "1                                 DP           @djcp87   Nov 1     False   \n",
      "2                                002      @baleriebear     19h     False   \n",
      "3                   Waluigi Galleani   @Thedoomscrolls     18h     False   \n",
      "4                      Dan Povenmire     @DanPovenmire  Oct 31     False   \n",
      "5                 Indie (COMMS OPEN)    @burntcinnabun  Oct 31     False   \n",
      "6                            appaboy          @appaboy   Nov 3     False   \n",
      "7                 Snoc Makes Friends          @SnocHog     18h     False   \n",
      "8                        Leezer Beam       @pickleknee   Nov 1     False   \n",
      "9                      BryBryBlessed    @BryBryBlessed     18h      True   \n",
      "10  The Simpsons Predicted Evey Word  @SimpsonAllWords      1h     False   \n",
      "\n",
      "   reply_to_handle  \n",
      "0                   \n",
      "1                   \n",
      "2                   \n",
      "3                   \n",
      "4                   \n",
      "5                   \n",
      "6                   \n",
      "7                   \n",
      "8                   \n",
      "9          @jeshvs  \n",
      "10                  \n"
     ]
    }
   ],
   "source": [
    "def parse_text(text):\n",
    "    # split by new line\n",
    "    text_list = str.splitlines(text) \n",
    "    # get the username (always the first list element)\n",
    "    username = text_list[0]  \n",
    "    # within the first few elements, find the element\n",
    "    # with the @ symbol, this will be the user handle\n",
    "    handle = ''.join(x for x in text_list[1:3] if '@' in x)\n",
    "    # get the date, using the single dot to identify its \n",
    "    # index location\n",
    "    dot_position = text_list[1:4].index('·')  \n",
    "    date = text_list[dot_position + 2]  # date comes after dot\n",
    "    # check if its a reply to someone else\n",
    "    if text_list[4] == \"Replying to \":\n",
    "        reply_to = True\n",
    "        reply_to_handle = text_list[5]\n",
    "        text = text_list[6]\n",
    "    else:\n",
    "        reply_to = False\n",
    "        reply_to_handle = ''\n",
    "        # find the longest string within list index 4:6\n",
    "        # this will be the tweet text\n",
    "        text = max(text_list[4:6], key=len)\n",
    "    # return the variables we have parse from the text\n",
    "    return pd.Series([username, handle,\n",
    "                      date, reply_to, reply_to_handle, text])\n",
    "# run the parse function via pandas apply\n",
    "master_df[['username', 'handle', 'date', 'reply_to', 'reply_to_handle', 'all_text']] = master_df['all_text'].apply(parse_text)\n",
    "# export csv\n",
    "# df.to_csv('output.csv')\n",
    "print(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
